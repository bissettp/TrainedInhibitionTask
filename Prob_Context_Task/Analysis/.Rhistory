dnorm(x,mean = mu1, sd = sd1)*prior1)
}
curve(relative_probabilities(x,.5,.5),-1,1,ylim=c(0,1),
ylab = "Posterior P(TS 1)", xlab = "Shade Context (Black to White)")
par(new = T)
curve(relative_probabilities(x,.9,.1),-1,1,ylim=c(0,1),
col = 'red',xlab = "", ylab = "")
par(new = T)
curve(relative_probabilities(x,.1,.9),-1,1,ylim=c(0,1), col = 'blue',
xlab = "", ylab = "")
title("Effect of prior")
legend("topright",  legend = c("P(TS 1) = .5","P(TS 1) = .9","P(TS 1) = .1"),
lty=c(1,1,1), col=c(1,2,4),ncol=1, cex = .8)
#incorporate utility, weight probabilities by maximal utility possible
choice_probabilities = function(x,prior1, prior2, value1, value2) {
dnorm(x,mean = mu1, sd = sd1)*prior1*value1/
(dnorm(x,mean = mu2, sd = sd2)*prior2*value2+
dnorm(x,mean = mu1, sd = sd1)*prior1*value1)
}
#graph the two distributions and their relative likelihood assuming a flat prior
curve(dnorm(x,mean = mu1, sd = sd1), -1, 1,
ylim = c(0,2))
par(new = T)
curve(dnorm(x,mean = mu2*2, sd = sd2), -1, 1,
yaxt = "n", ylab = "",ylim = c(0,2))
par(new = T)
curve(dnorm(x,mean = mu2, sd = sd2)/
(dnorm(x,mean = mu2, sd = sd2)+dnorm(x,mean = mu1, sd = sd1)),
-1, 1, yaxt = "n", ylab = "", ylim = c(0,2), col = 'red')
curve(choice_probabilities(x,.5,.5,1,2),-1,1,ylim=c(0,1),
ylab = "Posterior P(TS 1)", xlab = "Shade Context (Black to White)")
par(new = T)
curve(choice_probabilities(x,.9,.1,1,2),-1,1,ylim=c(0,1),
col = 'red',xlab = "", ylab = "")
par(new = T)
curve(choice_probabilities(x,.1,.9,1,2),-1,1,ylim=c(0,1), col = 'blue',
xlab = "", ylab = "")
title("Effect of prior")
legend("topright",  legend = c("P(TS 1) = .5","P(TS 1) = .9","P(TS 1) = .1"),
lty=c(1,1,1), col=c(1,2,4),ncol=1, cex = .8)
curve(dnorm(x,mean = mu1, sd = sd1), -1, 1,
ylim = c(0,2))
par(new = T)
curve(dnorm(x,mean = mu2*2, sd = sd2), -1, 1,
yaxt = "n", ylab = "",ylim = c(0,2))
par(new = T)
curve(dnorm(x,mean = mu2, sd = sd2)/
(dnorm(x,mean = mu2, sd = sd2)+dnorm(x,mean = mu1, sd = sd1)),
-1, 1, yaxt = "n", ylab = "", ylim = c(0,2), col = 'red')
curve(dnorm(x,mean = mu1, sd = sd1), -1, 1,
ylim = c(0,2))
par(new = T)
curve(2*dnorm(x,mean = mu2, sd = sd2), -1, 1,
yaxt = "n", ylab = "",ylim = c(0,2))
par(new = T)
curve(dnorm(x,mean = mu2, sd = sd2)/
(dnorm(x,mean = mu2, sd = sd2)+dnorm(x,mean = mu1, sd = sd1)),
-1, 1, yaxt = "n", ylab = "", ylim = c(0,2), col = 'red')
curve(dnorm(x,mean = mu1, sd = sd1), -1, 1,
ylim = c(0,3))
par(new = T)
curve(2*dnorm(x,mean = mu2, sd = sd2), -1, 1,
yaxt = "n", ylab = "",ylim = c(0,2))
par(new = T)
curve(dnorm(x,mean = mu2, sd = sd2)/
(dnorm(x,mean = mu2, sd = sd2)+dnorm(x,mean = mu1, sd = sd1)),
-1, 1, yaxt = "n", ylab = "", ylim = c(0,2), col = 'red')
curve(dnorm(x,mean = mu1, sd = sd1), -1, 1,
ylim = c(0,3))
par(new = T)
curve(2*dnorm(x,mean = mu2, sd = sd2), -1, 1,
yaxt = "n", ylab = "",ylim = c(0,3))
par(new = T)
curve(dnorm(x,mean = mu1, sd = sd1)/
(dnorm(x,mean = mu1, sd = sd1)+dnorm(x,mean = mu2, sd = sd2)*2),
-1, 1, yaxt = "n", ylab = "", ylim = c(0,3), col = 'red')
curve(dnorm(x,mean = mu1, sd = sd1), -1, 1,
ylim = c(0,3))
par(new = T)
curve(2*dnorm(x,mean = mu2, sd = sd2), -1, 1,
yaxt = "n", ylab = "",ylim = c(0,3))
par(new = T)
curve(dnorm(x,mean = mu1, sd = sd1)/
(dnorm(x,mean = mu1, sd = sd1)+dnorm(x,mean = mu2, sd = sd2)),
-1, 1, yaxt = "n", ylab = "", ylim = c(0,3), col = 'red')
curve(dnorm(x,mean = mu1, sd = sd1), -1, 1,
ylim = c(0,3))
par(new = T)
curve(2*dnorm(x,mean = mu2, sd = sd2), -1, 1,
yaxt = "n", ylab = "",ylim = c(0,3))
par(new = T)
curve(dnorm(x,mean = mu1, sd = sd1)/
(dnorm(x,mean = mu1, sd = sd1)+dnorm(x,mean = mu2, sd = sd2)),
-1, 1, yaxt = "n", ylab = "", ylim = c(0,3), col = 'red')
par(new = T)
curve(dnorm(x,mean = mu1, sd = sd1)/
(dnorm(x,mean = mu1, sd = sd1)+dnorm(x,mean = mu2, sd = sd2)*2),
-1, 1, yaxt = "n", ylab = "", ylim = c(0,3), col = 'red')
curve(dnorm(x,mean = mu1, sd = sd1), -1, 1,
ylim = c(0,3))
par(new = T)
curve(2*dnorm(x,mean = mu2, sd = sd2), -1, 1,
yaxt = "n", ylab = "",ylim = c(0,3))
par(new = T)
curve(dnorm(x,mean = mu1, sd = sd1)/
(dnorm(x,mean = mu1, sd = sd1)+dnorm(x,mean = mu2, sd = sd2)*2),
-1, 1, yaxt = "n", ylab = "", ylim = c(0,3), col = 'red')
#Without hypothesis priors one should change their policy based on whether the
#context is > 0
#With recursive transition probability = .9, given you are in state 1, you
#should wait until the context = -.5 with these values:
mu1 = -.3
mu2 = .3
sd1 = .37
sd2 = .37
#calculate overlap of two normal distributions
min.f1f2 <- function(x, mu1, mu2, sd1, sd2) {
f1 <- dnorm(x, mean=mu1, sd=sd1)
f2 <- 2*dnorm(x, mean=mu2, sd=sd2)
pmin(f1, f2)
}
integrate(min.f1f2, -Inf, Inf, mu1=mu1, mu2=mu2, sd1=sd1, sd2=sd2)
x <- seq(from=-1, to=1,by=0.01)
curve(dnorm(x,-.3,.37), xlim=c(-1,1),
xlab = "Gray Spectrum", ylab = "Density")
segments(x, rep(0,length(x)),x,dnorm(x,-.3,.37) ,
col=grey.colors(length(x), start = 0, end = 1), lwd=2)
par(new = T)
curve(dnorm(x,-.3,.37), xlim=c(-1,1), ylab = "", xlab = "", lwd = 2)
curve(dnorm(x,-.3,.37), xlim=c(-1,1),
xlab = "Gray Spectrum", ylab = "Density")
segments(x, rep(0,length(x)),x,dnorm(x,-.3,.37) ,
col=grey.colors(length(x), start = 0, end = 1), lwd=2)
par(new = T)
curve(dnorm(x,.3,.37), xlim=c(-1,1), ylab = "", xlab = "")
segments(x, rep(0,length(x)),x,dnorm(x,.3,.37) ,
col=grey.colors(length(x), start = 0, end = 1), lwd=2)
par(new=T)
curve(dnorm(x,.3,.37), xlim=c(-1,1), ylab = "", xlab = "", lwd = 2)
par(new=T)
curve(dnorm(x,-.3,.37), xlim=c(-1,1), ylab = "", xlab = "", lwd = 2, lty = 3)
#show relative likelihood including a recursive transition probability of .9
#dashed line shows the likelihood given that one is in state 2 (mu = mu2)
#dotted line shows likelihood given one is in state 1
curve(choice_probabilities(x,.5,.5,1,2),-1,1,ylim=c(0,1),
ylab = "Posterior P(TS 1)", xlab = "Shade Context (Black to White)")
par(new = T)
curve(choice_probabilities(x,.9,.1,1,2),-1,1,ylim=c(0,1),
col = 'red',xlab = "", ylab = "")
par(new = T)
curve(choice_probabilities(x,.1,.9,1,2),-1,1,ylim=c(0,1), col = 'blue',
xlab = "", ylab = "")
title("Effect of prior")
legend("topright",  legend = c("P(TS 1) = .5","P(TS 1) = .9","P(TS 1) = .1"),
lty=c(1,1,1), col=c(1,2,4),ncol=1, cex = .8)
library(ggplot2)
library(plyr)
dataFiles <- Sys.glob("../Data/model_simulation.csv")
dfa = read.csv(dataFiles[2])
dfa$FB = factor(dfa$FB)
source('~/.active-rstudio-document', echo=TRUE)
dfa = read.csv("../Data/model_simulation.csv")
setwd("~/Box Sync/Programming/Experiments/Color_Structure/Analysis")
dfa = read.csv("../Data/model_simulation.csv")
head(dfa)
str(dfa)
m_data = read.csv("../Data/model_simulation.csv")
?select
library(dplyr)
library(ggplot2)
?select
select(m_data, ends_with("choice"))
str(m_data)
as.factor(select(m_data, ends_with("choice")))
select(m_data, ends_with("choice"))
factor(select(m_data, ends_with("choice")))
a=select(m_data, ends_with("choice"))
a
as.factor(a)
a(factor)
factor(a)
lapply(factor,a)
as.lapply(factor,a)
?lapply
lapply(a,factor)
lapply(a,as.factor)
b=lapply(a,as.factor)
str(a)
str(b)
head(b)
head(b)
head(a)
b=sapply(a,as.factor)
head(b)
str(b)
sapply(select(m_data, ends_with("choice")),as.factor)
str(m_data)
sapply(select(m_data, ends_with("choice")),as.factor)
b=sapply(select(m_data, ends_with("choice")),as.factor)
str(b)
b
head(b)
ii <- grep(glob2rx("_choice"), names(m_data))
ii
ii <- grep(glob2rx("*_choice"), names(m_data))
ii
m_data[ii] <- lapply(m_data[ii], as.factor)
str(m_data)
a = gather(m_data,'model','prob_ts1',c('ignore','single','optimal'))
library(dplyr)
a = gather(m_data,'model','prob_ts1',c('ignore','single','optimal'))
library(tidyr)
a = gather(m_data,'model','prob_ts1',c('ignore','single','optimal'))
?gather
str(m_data)
a
str(a)
a = gather(m_data,'model','prob_ts1',-X,-c_dis1)
str(m_data)
a = gather(m_data,'model','prob_ts1',-X,-c_dis, -state, -stim, -trial_count)
str(a)
a = gather(m_data,'model','prob_ts1',-X,-c_dis, -state, -stim, -trial_count, -context)
str(a)
?select
a = gather(m_data,'model','prob_ts1',one_of('ignore','optimal'))
str(a)
head(a)
a = gather(m_data,'model','prob_ts1',contains('ignore','single','optimal'))
a = gather(m_data,'model','prob_ts1',contains(one_of('ignore','single','optimal')))
a = gather(m_data,'model','prob_ts1',one_of('ignore','single','optimal'))
str(a)
head(a)
a = gather(m_data, 'model', 'x', contains('noisy'))
str(a)
head(a)
a = gather(m_data, 'noisy_model', 'noisy_conf', contains('noisy'))
str(a)
?spread
?select
str(m_data)
a = gather(m_data, 'noisy_model', 'noisy_conf', ends_with('noisy'))
str(a)
head(a)
a = select(m_data, contains('noisy'))
head(a)
?extract
a = select(m_data, contains('noisy')) %>%
gather('noisy_model','x')
head(a)
?separate
a = select(m_data, contains('noisy')) %>%
gather('noisy_model','choice',ends_with('choice')
)
str(a)
head(a)
a = select(m_data, contains('noisy')) %>%
gather('noisy_model_choice','noisy_choice',ends_with('choice') %>%
gather('noisy_model','noisy_conf',ends_with('noisy'))
)
a = select(m_data, contains('noisy')) %>%
gather('noisy_model_choice','noisy_choice',ends_with('choice')) %>%
gather('noisy_model','noisy_conf',ends_with('noisy'))
head(a)
dim(a)
a = select(m_data, contains('noisy')) %>%
gather('noisy_model_choice','noisy_choice',ends_with('choice'))
dim(a)
head(m_data)
a = select(m_data, -contains('noisy'))
str(a)
head(a)
a = select(m_data, contains('noisy'), -contains('choice'))
head(a)
select(m_data, contains('noisy'), -contains('choice')) %>%
gather('noisy_model','noisy_conf')
head(a)
a = select(m_data,-contains('choice'))
str(m_data)
a = select(m_data,-contains('choice')) %>%
gather('model','conf',contains('ignore','single','optimal'))
a = select(m_data,-contains('choice')) %>%
gather('model','conf',contains('ignore'),contains('single'),contains('optimal')))
?select
a = select(m_data,-contains('choice')) %>%
gather('model','conf',matches('ignore*|single*|optimal*'))
str(a)
head(a)
tail(a)
m_long$choice = m_long$conf > .5
m_long = select(m_data,-contains('choice')) %>%
gather('model','conf',matches('ignore*|single*|optimal*'))
m_long$choice = m_long$conf > .5
str(m_long)
m_long = select(m_data,-contains('choice')) %>%
gather('model','conf',matches('ignore*|single*|optimal*'))
m_long$choice = round(m_long$conf)
str(m_long)
ggplot(m_data, aes(context, conf, color = model) + geom_point()
ggplot(m_long, aes(context, conf, color = model)) + geom_point()
ggplot(m_long, aes(context, conf, color = model)) + geom_point(aes(alpha = .05))
ggplot(m_long, aes(context, conf, color = model)) + geom_point(aes(alpha = .05)) + geom_smooth(method = lm)
ggplot(m_long, aes(context, conf, color = model)) + geom_point(aes(alpha = .05)) +
geom_smooth()
str(m_long)
ggplot(m_long, aes(context, conf, color = model)) + geom_point(aes(alpha = .05), position = jitter) +
geom_smooth()
ggplot(m_long, aes(context, conf, color = model)) + geom_point(position = jitter) +
geom_smooth()
ggplot(data =m_long, aes(context, conf, color = model)) + geom_point(aes(alpha = .05), position = jitter) +
geom_smooth()
ggplot(data =m_long, aes(context, conf, color = model)) + geom_point(aes(alpha = .0001)) +
geom_smooth()
str(m_long)
str(m_data)
?extract
?separate
tail(m_long)
separate(m_long,model,c("model","noisy_model"), sep = "_noisy")
separate(m_long,model,c("model","noisy_model"), sep = "_")
m_long[like(model,"_noisy")]
m_long[model %like% "noisy"]
m_long[grep(model,"noisy")]
m_long[grep("noisy",model)]
str(m_long)
m_long[grep("noisy",model)]
?grep
m_long[grep("*noisy",model)]
m_long[grep("*noisy",m_long$model)]
m_long[grep("noisy",m_long$model)]
grep("noisy",m_long$model)
grep("noisy",m_long$model)
m_long[grep("noisy",m_long$model),]
noisy_rows = grep("noisy",m_long$model)
m_noisy_long = m_long[noisy_rows,]
m_long = m_long[-noisy_rows,]
ggplot(data =m_long, aes(context, conf, color = model)) + geom_point(aes(alpha = .0001)) +
geom_smooth()
head(m_long)
filter(m_long,trial_count==1)
filter(m_long,context = 0)
filter(m_long,context == 0)
filter(m_long,context == -.1)
filter(m_long,context == -0.1)
filter(m_long,trial_count == 3)
filter(m_long,context == .1)
filter(m_long,context == .1)
m_long$context
m_long$context==.1
round(m_long$context)
round(m_long$context,1)
m_data = read.csv("../Data/model_simulation.csv")
## Get indices of columns to convert
ii <- grep(glob2rx("*_choice"), names(m_data))
## Convert and replace the indicated columns
m_data[ii] <- lapply(m_data[ii], as.factor)
m_data$context = round(m_long$context,1)
m_data = read.csv("../Data/model_simulation.csv")
ii <- grep(glob2rx("*_choice"), names(m_data))
m_data[ii] <- lapply(m_data[ii], as.factor)
m_data$context = round(m_long$context,1)
m_data$context = round(m_data$context,1)
m_long = select(m_data,-contains('choice')) %>%
gather('model','conf',matches('ignore*|single*|optimal*'))
m_long$choice = round(m_long$conf)
noisy_rows = grep("noisy",m_long$model)
m_noisy_long = m_long[noisy_rows,]
m_long = m_long[-noisy_rows,]
filter(m_long, context == .1)
filter(m_long, context == .3)
filter(m_data,context == .1)
filter(m_data,context < .5)
filter(m_data,context < .5 and context > -.5)
filter(m_data,context < .5 & context > -.5)
filter(m_data,context < .5 & context > 0)
filter(m_data,context < .31 & context > 0)
filter(m_data,context < .31 & context > -.2)
filter(m_data,context < .31 & context > -.1)
filter(m_data,context < .31 & context > .12)
ggplot(data = filter(m_long, context < .35 & context > -.35), aes(context, conf, color = model)) + geom_point(aes(alpha = .0001)) +
geom_smooth()
ggplot(data = filter(m_long, context < .35 & context > -.35 % model = 'optimal'), aes(context, conf, color = model)) + geom_point(aes(alpha = .0001)) + geom_smooth()
ggplot(data = filter(m_long, context < .35 & context > -.35 & model == 'single'), aes(context, conf, color = model)) + geom_point(aes(alpha = .0001)) + geom_smooth()
ggplot(data = filter(m_long, context < .35 & context > -.35 & model == 'single'), aes(context, conf, color = model)) +
geom_point(position = 'jitter') + geom_smooth()
ggplot(data = filter(m_long, context < .35 & context > -.35 & model == 'ignore'), aes(context, conf, color = model)) +
geom_point(position = 'jitter') + geom_smooth()
ggplot(data = filter(m_long, context < .35 & context > -.35 & model == 'optimal'), aes(context, conf, color = model)) +
geom_point(position = 'jitter') + geom_smooth()
ggplot(data = filter(m_long, context < .35 & context > -.35 & model == 'optimal'), aes(context, conf, color = model)) +
geom_point(aes(alpha = .001)) + geom_smooth()
ggplot(data = filter(m_long, context < .35 & context > -.35 & model == 'optimal'), aes(context, conf, color = model)) +
geom_point(aes(alpha = .001), position = 'jitter') + geom_smooth()
ggplot(data = filter(m_long,  model == 'optimal'), aes(context, conf, color = model)) +
geom_point(aes(alpha = .001), position = 'jitter') + geom_smooth()
ggplot(data = filter(m_long,  model == 'optimal', color = choice), aes(context, conf, color = model)) +
geom_point(aes(alpha = .001), position = 'jitter') + geom_smooth()
str(m_long)
m_long$choice = as.factor(round(m_long$conf))
noisy_rows = grep("noisy",m_long$model)
m_noisy_long = m_long[noisy_rows,]
m_long = m_long[-noisy_rows,]
m_long = select(m_data,-contains('choice')) %>%
gather('model','conf',matches('ignore*|single*|optimal*'))
m_long$choice = as.factor(round(m_long$conf))
noisy_rows = grep("noisy",m_long$model)
m_noisy_long = m_long[noisy_rows,]
m_long = m_long[-noisy_rows,]
ggplot(data = filter(m_long,  model == 'optimal', color = choice), aes(context, conf, color = model)) +
geom_point(aes(alpha = .001), position = 'jitter') + geom_smooth()
ggplot(data = filter(m_long,  model == 'optimal'), aes(context, conf, color = model)) +
geom_point(aes(alpha = .001), position = 'jitter') + geom_smooth()
ggplot(data = filter(m_long,  model == 'optimal'), aes(context, conf, color = choice)) +
geom_point(aes(alpha = .001), position = 'jitter') + geom_smooth()
ggplot(data = filter(m_long,  model == 'single'), aes(context, conf, color = choice)) +
geom_point(aes(alpha = .001), position = 'jitter') + geom_smooth()
ggplot(data = filter(m_long,  model == 'ignore'), aes(context, conf, color = choice)) +
geom_point(aes(alpha = .001), position = 'jitter') + geom_smooth()
ggplot(data = filter(m_long,  model == 'optimal'), aes(context, conf, color = choice)) +
geom_point(aes(alpha = .001), position = 'jitter') + geom_smooth()
ggplot(data = filter(m_long,  model == 'optimal'), aes(context, conf, color = choice)) +
geom_point(aes(alpha = .001), position = 'jitter') + geom_smooth()
ggplot(data = filter(m_long,  model == 'optimal'), aes(context, conf) +
geom_point(aes(alpha = .001), position = 'jitter') + geom_smooth()
ggplot(data = filter(m_long,  model == 'optimal'), aes(context, conf)) +
geom_point(aes(alpha = .001), position = 'jitter') + geom_smooth()
m_long = select(m_data,-contains('choice')) %>%
gather('model','conf',matches('ignore*|single*|optimal*'))
m_long$choice = as.factor(round(m_long$conf))
dim(m_long)
?filter
ggplot(data = filter(m_long,  model == 'single'), aes(context, conf)) +
geom_point(aes(alpha = .001), position = 'jitter') + geom_smooth()
ggplot(data = filter(m_long,  model == 'context'), aes(context, conf)) +
geom_point(aes(alpha = .001), position = 'jitter') + geom_smooth()
ggplot(data = filter(m_long,  model == 'optimal), aes(context, conf)) +
geom_point(aes(alpha = .001), position = 'jitter') + geom_smooth()
ggplot(data = filter(m_long,  model == 'optimal'), aes(context, conf)) +
geom_point(aes(alpha = .001), position = 'jitter') + geom_smooth()
ggplot(data = filter(m_long,  model == 'optimal'), aes(context, conf, color = ts)) +
geom_point(aes(alpha = .001), position = 'jitter') + geom_smooth()
str(m_long)
m_long$ts = as.factor(m_long$ts)
ggplot(data = filter(m_long,  model == 'optimal'), aes(context, conf, color = ts)) +
geom_point(aes(alpha = .001), position = 'jitter') + geom_smooth()
lagpad(m_data$ts)
lagpad <- function(x, k) {
if(k > 0) {
c(rep(NA, k), x)[1 : length(x)]
} else {
c(x, rep(NA, abs(k)))[abs(k)+1 : length(x)]
}}
lagpad(m_data$ts)
lagpad(m_data$ts,1)
m_data = read.csv("../Data/model_simulation.csv")
## Get indices of columns to convert
ii <- grep(glob2rx("*_choice"), names(m_data))
## Convert and replace the indicated columns
m_data[ii] <- lapply(m_data[ii], as.factor)
m_data$context = round(m_data$context,1)
m_data$ts = as.factor(m_data$ts)
m_data$last_ts = as.factor(lagpad(m_data$ts,1))
head(m_data)
m_long = select(m_data,-contains('choice')) %>%
gather('model','conf',matches('ignore*|single*|optimal*'))
m_long$choice = as.factor(round(m_long$conf))
noisy_rows = grep("noisy",m_long$model)
m_noisy_long = m_long[noisy_rows,]
m_long = m_long[-noisy_rows,]
ggplot(data = filter(m_long,  model == 'optimal'), aes(context, conf, color = last_ts)) +
geom_point(aes(alpha = .001), position = 'jitter') + geom_smooth()
ggplot(data = m_long, aes(context, conf, color = last_ts)) +
geom_point(aes(alpha = .001), position = 'jitter') + geom_smooth() +
facet_grid(.~model)
ggplot(data = m_long, aes(context, conf, color = last_ts)) +
geom_point(aes(alpha = .001), position = 'jitter') + geom_smooth() +
facet_grid(model~.)
ggplot(data = m_long, aes(context, conf, color = model)) +
geom_point(aes(alpha = .001), position = 'jitter') + geom_smooth() +
facet_grid(last_ts~.)
ggplot(data = m_long, aes(context, conf, color = last_ts)) +
geom_point(aes(alpha = .001), position = 'jitter') + geom_smooth() +
facet_grid(model~.)
str(m_data)
glm(optimal_choice ~ context + last_ts, family = binomial, data = m_data)
glm_optimal = glm(optimal_choice ~ context + last_ts, family = binomial, data = m_data)
summary(glm_optimal)
glm_ignore = glm(ignore_choice ~ context + last_ts, family = binomial, data = m_data)
summary(glm_ignore)
glm_ignore = glm(ignore_choice ~ context + last_ts, family = binomial, data = m_data)
glm_optimal = glm(optimal_choice ~ context + last_ts, family = binomial, data = m_data)
summary(glm_optimal)
glm_ignore = glm(ignore_choice ~ context + last_ts, family = binomial, data = m_data)
summary(glm_ignore)
str(m_data)
glm_ignore = glm(ignore_noisy_choice ~ context + last_ts, family = binomial, data = m_data)
summary(glm_ignore)
glm_optimal = glm(optimal_noisy_choice ~ context + last_ts, family = binomial, data = m_data)
summary(glm_optimal)
glm_single = glm(single_noisy_choice ~ context + last_ts, family = binomial, data = m_data)
summary(glm_single)
glm_all = glm(single_noisy_choice ~ optimal_noisy + single_noisy + ignore_noisy, family = binomial, data = m_data)
glm_all = glm(ignore_noisy_choice ~ optimal_noisy + single_noisy + ignore_noisy, family = binomial, data = m_data)
glm_all = glm(optimal_noisy_choice ~ optimal_noisy + single_noisy + ignore_noisy, family = binomial, data = m_data)
glm_all = glm(optimal_noisy_choice ~ optimal + single + ignore, family = binomial, data = m_data)
summary(glm_all)
glm_all = glm(single_noisy_choice ~ optimal + single + ignore, family = binomial, data = m_data)
glm_all = glm(ignore_noisy_choice ~ optimal + single + ignore, family = binomial, data = m_data)
summary(glm_all)
glm_all = glm(single_noisy_choice ~ optimal + single + ignore, family = binomial, data = m_data)
summary(glm_all)
m_data$single_noisy_choice
m_data$single_noisy_choice == m_data$single_choice
